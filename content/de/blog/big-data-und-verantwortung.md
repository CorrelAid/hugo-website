---
 title: "Big Data und Verantwortung"
 date: 2017-11-07T00:00:00+02:00
 image: "509-bayreuth.jpg"
 summary: "Ein Besuch bei den Bayreuther Dialogen"
 author: "Vera"
---


*Die Bayreuther Dialoge der Universität Bayreuth bezeichnen sich selbst
als „Zukunftsforum für Ökonomie, Philosophie und Gesellschaft“. Sie
bieten den Rahmen, dass sich Interessierte aus allen Bereichen der
Gesellschaft austauschen können. Dieses Jahr ging es um Verantwortung –
und Vera von CorrelAid war mit dabei. Natürlich ging es dabei auch um
Daten und deren Nutzung.*

Der Begriff Verantwortung ist zunächst ein sehr weiter Begriff. Vor
allem der **verantwortungsvolle Umgang mit Daten** im Allgemeinen ist
ein sehr komplexes Thema, der viele Bereiche von Privatsphäre über
staatliche Regulierung von Unternehmen und den Staat selbst betrifft.

Doch um über Verantwortung und Big Data sprechen zu können, muss
zunächst eine Grundlage für diese Debatte geschaffen werden, die
aufklärt, um was es eigentlich geht, wenn wir den Begriff Big Data
verwenden. Insbesondere müssen die Menschen einschätzen können, **wo das
Potential und die Gefahren liegen.**

Wenn wir über Big Data sprechen, geht es um sehr große Datenmengen.
Diese großen Datenmengen erlauben es, Algorithmen in einer Weise
anzuwenden, die effektiver ist als jemals zuvor. Vor allem in dem
Bereich künstliche Intelligenz lernen Algorithmen, Erkenntnisse aus
solchen großen Datenmengen zu ziehen. **Algorithmen sind überall und
beeinflussen bereits unsere alltäglichen Entscheidungen.** Wenn wir
Google Maps benutzen, um von A nach B zu kommen, wenn wir Produkte
online kaufen. Algorithmen werden aber auch bei der Analyse der
Kreditwürdigkeit von Personen angewandt oder in der Personalauswahl in
Unternehmen und in der Forensik.

*„Algorithmen machen unser Leben effizienter.“*

Während eines zweistündigen Seminars haben wir bei den Bayreuther
Dialogen lange über das Potential und die Gefahren gesprochen, die bei
der Anwendung von Algorithmen entstehen. Das Potential bei der Anwendung
von Algorithmen ist recht offensichtlich. Sie machen unser Leben
effizienter und **Entscheidungen werden weniger komplex**. Sie helfen
uns sogar, bessere Entscheidungen zu treffen.

Die Risiken sind jedoch ebenfalls recht offensichtlich. Sie fangen bei
dem Betriebsgeheimnis von Unternehmen an, die nicht offenlegen wollen,
welchen Algorithmus sie verwenden, um zu bestimmten Ergebnissen zu
kommen und auch nicht transparent kommunizieren, welche Daten sie
verwenden, um den Algorithmus zu trainieren. Noch verheerender jedoch
ist, dass nur in den seltensten Fällen eine Feedbackschleife existiert,
die dem Algorithmus in irgendeiner Weise beibringt, ob der Output, den
er erzeugt hat, positiv oder negativ war. Schon alleine der Datensatz
kann unvollständig sein, oder zu wenige Fälle abdecken und so zu
verzerrten Ergebnissen führen. Wie zum Beispiel bei der US-Justiz, wo
Algorithmen verwendet werden, um das Rückfallrisiko von Angeklagten zu
berechnen. Dieses Programm heißt Compas (Correctional Offender
Management Profiling for Alternative Sanctions) und diskriminiert
Angeklagte mit dunkler Hautfarbe, in dem für sie eine fast doppelt so
hohe Rückfälligkeitsquote berechnet wird, wie bei Angeklagten mit heller
Hautfarbe. Das liegt mitunter an den ausgewählten Indikatoren, um eine
Rückfallwahrscheinlichkeit vorauszusagen. Bei solchen Beispielen liegt
das weit größere Problem allerdings in der Geheimhaltung der
Unternehmen, die eine Überprüfung des Algorithmus nicht zulassen, wegen
des Geschäftsgeheimnisses. **So bleiben die Algorithmen meist „Black
Boxes“, die ohne ausreichende Tests und Überprüfung für die
Zivilgesellschaft eingesetzt werden**. Für die Anwendung und Überprüfung
von Algorithmen benötigen wir dringend ein Überprüfungsorgan, welches
Fehler verhindert, die eine verheerende Auswirkung auf das Leben
einzelner haben kann.

Dieses Thema haben wir in einer Podiumsdiskussion aufgegriffen und rege
diskutiert. Mit dabei waren Nikolaus Blome (der stellvertretende
Chefredakteur der „BILD“), Denny Vorbrücken (stellvertretender
Personalratsvorsitzender des Bundeskriminalamtes), Daniel Domscheit-Berg
(Netzaktivist). In der Debatte haben vor allem Domscheit-Berg und ich
**fehlende Transparenz und Kommunikation** betont wenn es darum geht,
was mit den Daten passiert, die große Konzerne und der Staat sammeln und
auswerten.

Es ist längst an der Zeit, auch den „Cyber Space“ als Rechtsraum
anzuerkennen und anstatt unklarer Verantwortungsbereiche klare Rechte
für Unternehmen und das Individuum zu schaffen. Vor allem braucht es
jedoch Aufklärung. Aufklärung darüber, was Daten sind, was damit gemacht
werden kann und wo die eigenen Daten inzwischen überall verstreut sind.
Aufklärung sollte bereits in der Schule beginnen. Vor allem, betonte
Daniel Domscheit-Berg, dass in Schulen noch viel zu wenig Möglichkeiten
geschaffen werden, sich mit dem Thema Daten und Programmieren
auseinanderzusetzen. **Wir brauchen datenmündige Bürger!**

Denny Vorbrücken schilderte Teile der Datenauswertung des BKA. Diese sei
in einigen Fällen hilfreich gewesen. Durch Datentriangulation konnte das
BKA bereits Zusammenhänge herstellen zwischen einzelnen Personen und
mehreren Orten, an denen Verbrechen verübt worden waren. Allerdings
werden die Daten auch schon bei sehr kleinen Delikten erhoben und
gespeichert. Auf die Frage, ob diese Daten wieder gelöscht werden,
antwortete Denny Vorbrücken zwar mit einem klaren „Ja!“. Doch bleibt
unklar, nach welchem Zeitraum sie gelöscht werden. Denn wie Vorbrücken
schilderte, werden die Daten verwendet, um ein Muster von Individuen zu
erkennen: Tauchen sie an mehreren Tatorten auf? Dazu müssen die Daten
allerdings über einen längeren Zeitraum gespeichert werden, damit es
überhaupt möglich ist, ein Muster über fünf bis zehn Jahre zu erkennen.
Nikolaus Blume äußerte sich zu der Schwierigkeit der Regulierung von
Unternehmen. Er sagte, dass wenn die EU eine gemeinsame Regulierung
fände zu Datenschutz und Privatsphäre im Netz, dass Unternehmen wie
Google und Facebook diese dann auch befolgen würden.

Die wichtigsten Forderungen, die aus der Podiumsdiskussion hervorgingen,
waren einerseits klare Rechte, wem die Daten gehören, wie sie genutzt
werden dürfen und wer sie nutzen darf. Wir brauchen überdies eine
Definition, was Privatsphäre im Netz bedeutet und wie wir damit umgehen.
Letztlich brauchen wir auch mehr Aufklärung zum Thema Daten und
Datennutzung.

*Mein persönlicher Eindruck, den ich von den Bayreuther Dialogen
mitgenommen habe, war, dass unsere Gesellschaft langsam mehr Interesse
für dieses Thema zeigt, es jedoch so komplex geworden ist, dass es sehr
schwer fällt, einen Zugang dazu zu finden. Wir brauchen nicht nur mehr
DatenanalystInnen, die die effizienten Technologien für soziale
Organisationen einsetzen, sondern auch DatenanalystInnen, die am
Aufklärungsprozess für die Zivilbevölkerung mithelfen.*

------------------------------------------------------------------------


